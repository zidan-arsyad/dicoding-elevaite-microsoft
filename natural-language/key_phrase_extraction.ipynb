{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Phrase Extraction\n",
    "\n",
    "Key phrase extraction identifies the main points from text.\n",
    "1. Use sentiment analysis to determine the sentiment of a review.\n",
    "2. Key phrase extraction to identify important elements of the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Method|Best For|Pros|Cons\n",
    "---|---|---|---\n",
    "spaCy (Noun Chunks)|Simple phrase extraction|Fast, rule-based|No ranking, misses verbs\n",
    "YAKE|Unsupervised keyword extraction|No training needed, good for short texts|No deep understanding of meaning\n",
    "KeyBERT|Deep semantic key phrases|Context-aware, best for accuracy|Needs more resources\n",
    "RAKE|Phrase-based extraction|Works well for long documents|Can pick up unimportant phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SpaCy + noun chunks (basic method)\n",
    "\n",
    "Extracts noun phrases (good for short key phrases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros:** Fast and simple\\\n",
    "**Cons:** Doesn't rank importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_short_text = \"Elon Musk founded SpaceX and Tesla, leading innovations in space travel and electric cars.\"\n",
    "\n",
    "sample_long_text = \"\"\"\n",
    "    Artificial Intelligence (AI) has rapidly evolved over the past few decades, transforming industries, reshaping economies, and revolutionizing human interactions with technology. The journey of AI began in the mid-20th century when pioneers like Alan Turing and John McCarthy laid the theoretical foundations for machine intelligence. Early AI systems focused on rule-based approaches and expert systems, which, although powerful for specific tasks, lacked the adaptability of modern machine learning models.\n",
    "    With the rise of deep learning in the 2010s, AI took a significant leap forward. Neural networks, inspired by the structure of the human brain, enabled machines to recognize speech, translate languages, and even generate realistic images. Companies like Google, OpenAI, and Tesla leveraged deep learning to create state-of-the-art AI applications. Self-driving cars, natural language processing (NLP), and recommendation algorithms became mainstream.\n",
    "    Despite these advancements, AI still faces ethical and technical challenges. Bias in AI models, data privacy concerns, and the impact of automation on employment are widely debated topics. Researchers continue to develop responsible AI frameworks to ensure fairness, transparency, and accountability in AI-driven decision-making.\n",
    "    Looking ahead, AI is expected to become even more integrated into daily life. Innovations in healthcare, education, and robotics promise to enhance human capabilities while raising important ethical considerations. As AI progresses, balancing innovation with ethical responsibility will be crucial for shaping a future where artificial intelligence benefits all of humanity.\n",
    "\"\"\"\n",
    "\n",
    "sample_long_text = sample_long_text.replace(\"\\n\", \"\")\n",
    "sample_long_text = sample_long_text.replace(\"    \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun Phrases in Short Text:\n",
      "['Elon Musk', 'SpaceX', 'Tesla', 'leading innovations', 'space travel', 'electric cars']\n",
      "\n",
      "Noun Phrases in Long Text:\n",
      "['Artificial Intelligence', '(AI', 'the past few decades', 'transforming industries', 'economies', 'human interactions', 'technology', 'The journey', 'AI', 'the mid-20th century', 'pioneers', 'Alan Turing', 'John McCarthy', 'the theoretical foundations', 'machine intelligence', 'Early AI systems', 'rule-based approaches', 'expert systems', 'which', 'specific tasks', 'the adaptability', 'modern machine learning models', 'the rise', 'deep learning', 'AI', 'a significant leap', 'Neural networks', 'the structure', 'the human brain', 'machines', 'speech', 'translate languages', 'realistic images', 'Companies', 'Google', 'OpenAI', 'Tesla', 'deep learning', 'the-art', 'AI', 'Self-driving cars', 'natural language processing', 'NLP', 'recommendation algorithms', 'these advancements', 'AI', 'ethical and technical challenges', 'Bias', 'AI models', 'data privacy concerns', 'the impact', 'automation', 'employment', 'widely debated topics', 'Researchers', 'responsible AI frameworks', 'fairness', 'transparency', 'accountability', 'AI-driven decision-making', 'AI', 'daily life', 'Innovations', 'healthcare', 'education', 'robotics', 'human capabilities', 'important ethical considerations', 'AI', 'innovation', 'ethical responsibility', 'a future', 'all', 'humanity']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model for spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the texts\n",
    "short_text_doc = nlp(sample_short_text)\n",
    "long_text_doc = nlp(sample_long_text)\n",
    "\n",
    "# Extract noun phrases from the texts\n",
    "short_text_noun_phrases = [chunk.text for chunk in short_text_doc.noun_chunks]\n",
    "long_text_noun_phrases = [chunk.text for chunk in long_text_doc.noun_chunks]\n",
    "\n",
    "# Display the noun phrases\n",
    "print(\"Noun Phrases in Short Text:\")\n",
    "print(short_text_noun_phrases)\n",
    "print(\"\\nNoun Phrases in Long Text:\")\n",
    "print(long_text_noun_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YAKE (unsupervised keyword extraction)\n",
    "\n",
    "Detects important phrases without training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros:** More intelligent than noun chunks, includes verb phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords in Short Text:\n",
      "['Elon Musk', 'Musk founded', 'leading innovations', 'electric cars', 'founded SpaceX']\n",
      "\n",
      "Keywords in Long Text:\n",
      "['transforming industries', 'reshaping economies', 'rapidly evolved', 'Alan Turing', 'Artificial Intelligence']\n"
     ]
    }
   ],
   "source": [
    "from yake import KeywordExtractor\n",
    "\n",
    "# Initialize YAKE\n",
    "keyword_extractor = KeywordExtractor(n=2, top=5)\n",
    "\n",
    "# Extract keywords from the texts\n",
    "short_text_keywords = keyword_extractor.extract_keywords(sample_short_text)\n",
    "long_text_keywords = keyword_extractor.extract_keywords(sample_long_text)\n",
    "\n",
    "# Display the keywords\n",
    "print(\"Keywords in Short Text:\")\n",
    "print([stk[0] for stk in short_text_keywords])\n",
    "print(\"\\nKeywords in Long Text:\")\n",
    "print([ltk[0] for ltk in long_text_keywords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KeyBERT (BERT-based for semantic key phrases)\n",
    "\n",
    "Uses BERT embeddings to find the most relevant words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros:** Context-aware and captures meaning, not just frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords in Short Text:\n",
      "['musk founded', 'spacex tesla', 'elon musk', 'founded spacex', 'tesla']\n",
      "\n",
      "Keywords in Long Text:\n",
      "['ai driven', 'advancements ai', 'ai frameworks', 'responsible ai', 'ai']\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "# Initialize KeyBERT\n",
    "keybert_model = KeyBERT()\n",
    "\n",
    "# Extract keywords from the texts\n",
    "short_text_keywords = keybert_model.extract_keywords(\n",
    "    sample_short_text, keyphrase_ngram_range=(1, 2), stop_words=\"english\"\n",
    ")\n",
    "long_text_keywords = keybert_model.extract_keywords(\n",
    "    sample_long_text, keyphrase_ngram_range=(1, 2), stop_words=\"english\"\n",
    ")\n",
    "\n",
    "# Display the keywords\n",
    "print(\"Keywords in Short Text:\")\n",
    "print([stk[0] for stk in short_text_keywords])\n",
    "print(\"\\nKeywords in Long Text:\")\n",
    "print([ltk[0] for ltk in long_text_keywords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAKE (Rapid Automatic Keyword Extraction)\n",
    "\n",
    "Extracts multi-word key phrases based on word frequency & co-occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros:** Good for multi-word key phrases, but may not be as accurate as BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords in Short Text:\n",
      "['elon musk founded spacex', 'space travel', 'leading innovations', 'electric cars', 'tesla']\n",
      "\n",
      "Keywords in Long Text:\n",
      "['recommendation algorithms became mainstream', 'pioneers like alan turing', 'raising important ethical considerations', 'even generate realistic images', 'develop responsible ai frameworks']\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "# Initialize Rake\n",
    "r = Rake()\n",
    "\n",
    "# Extract keywords from the texts\n",
    "r.extract_keywords_from_text(sample_short_text)\n",
    "short_text_keywords = r.get_ranked_phrases()\n",
    "\n",
    "r.extract_keywords_from_text(sample_long_text)\n",
    "long_text_keywords = r.get_ranked_phrases()\n",
    "\n",
    "# Display the keywords\n",
    "print(\"Keywords in Short Text:\")\n",
    "print(short_text_keywords[:5])\n",
    "print(\"\\nKeywords in Long Text:\")\n",
    "print(long_text_keywords[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
