{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Tagging\n",
    "1. Tensorflow (EfficientNet)\n",
    "2. OpenCV (SIFT Feature Extraction)\n",
    "3. PyTorch (ResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensorflow (EfficentNet)\n",
    "Pretrained model from tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = EfficientNetB0(weights='imagenet')\n",
    "\n",
    "\n",
    "def tf_tag_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    labels = decode_predictions(predictions, top=5)[0]\n",
    "\n",
    "    print('Predicted labels:')\n",
    "    for label in labels:\n",
    "        print(f'{label[1]} (Confidence: {label[2]:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted labels:\n",
      "shopping_basket (Confidence: 0.48)\n",
      "grocery_store (Confidence: 0.31)\n",
      "confectionery (Confidence: 0.07)\n",
      "shoe_shop (Confidence: 0.02)\n",
      "tobacco_shop (Confidence: 0.02)\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "\n",
    "tf_tag_image('store-camera-2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OpenCV (SIFT Feature Extraction)\n",
    "Only extracts unique features, not labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_extract_feature(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\n",
    "    print(f'Detected {len(keypoints)} keypoints in the image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 2507 keypoints in the image\n"
     ]
    }
   ],
   "source": [
    "cv2_extract_feature('store-camera-2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PyTorch (ResNet50)\n",
    "Transfer learning model. Image tagging with ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained resnet50 model\n",
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.eval()\n",
    "\n",
    "# define preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load ImageNet labels\n",
    "with open(\"imagenet_classes.txt\") as f:\n",
    "    labels_map = [line.strip() for line in f.readlines()]\n",
    "\n",
    "\n",
    "def torch_tag_image(img_path, confidence_threshold=0.2):\n",
    "    img = Image.open(img_path)\n",
    "    img = transform(img).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "\n",
    "    # convert to probabilities using softmax\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "\n",
    "    # get sorted indices for predictions\n",
    "    sorted_indices = torch.argsort(probabilities, descending=True)\n",
    "\n",
    "    print(\n",
    "        f'Predicted labels with confidence threshold {confidence_threshold}:')\n",
    "    for idx in sorted_indices:\n",
    "        confidence = probabilities[idx].item()\n",
    "        if confidence >= confidence_threshold:\n",
    "            print(f'{labels_map[idx]} (Confidence: {confidence:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels with confidence threshold 0.5:\n",
      "shopping basket (Confidence: 0.76)\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "torch_tag_image('store-camera-2.jpg', confidence_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "1. Image caption\n",
    "2. Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
